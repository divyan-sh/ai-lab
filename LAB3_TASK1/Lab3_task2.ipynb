{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tabulate sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "\n",
    "This notebook will introduce you the basics of Naive Bayes Algorithm for classification tasks. It includes the following content:\n",
    "\n",
    "- Brief overview of the Naive Bayes (NB) Classifier\n",
    "- An example exercise of performing inference with NB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a classifier?\n",
    "\n",
    "A classifier is a machine learning model that is used to discriminate different objects based on certain features. Given sample data $X$, a classifier predicts the class $y$ it belongs to.\n",
    "\n",
    "## What is Naive Bayes Classifier?\n",
    "\n",
    "A Naive Bayes classifier is a probabilistic machine learning model for classification task. It is based on Bayes theorem and imposes a strong assumption on feature independence.\n",
    "\n",
    "## Bayes Theorem\n",
    "\n",
    "$$ P(A \\mid B) = \\frac{P(B \\mid A) \\, P(A)}{P(B)} $$\n",
    "\n",
    "We can compute the probability of event A happening, given the fact that event B has occurred. Event B is the evidence and event A is the hypothesis. The assumption made by Naive Bayes is that the features are independent, i.e. the presence of one feature does not affect the other. Therefore it is called naive.\n",
    "\n",
    "Under the context of classification tasks, given the observation $X$, the classifier casts prediction on the class $y$. It can also be rewritten (with $y$ and $X$ replacing $A$ and $B$) as\n",
    "\n",
    "$$ P(y \\mid X) = \\frac{P(X \\mid y) \\, P(y)}{P(X)} $$\n",
    "\n",
    "The formula consists of four components:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\n",
    "P(y \\mid X) :\n",
    "\\:$ The posterior probability, which is the probability of class $y$ given the observation $X$\n",
    "\n",
    "- $\n",
    "P(y) :\n",
    "\\:$ The Prior probability, which is the prior probability (initial belief) of class $y$\n",
    "\n",
    "- $\n",
    "P(X \\mid y) :\n",
    "\\:$The Likelihood, which is the probability of obsevation $X$ given class $y$.\n",
    "\n",
    "- $\n",
    "P(X) :\n",
    "\\:$The Evidence, which is the probability of obsevation $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In classification tasks, the variable $y$ is the class label. The variable X represent the parameters/features and it usually contains multiple features/dimensions:\n",
    "\n",
    "$$ X = (x_1, x_2, x_3, ..., x_n) $$\n",
    "\n",
    "where $x_1, x_2, ..., x_n$ are the features and they are assumed to be independent in NB, i.e. $ (\\:x_i \\: \\bot \\:  x_j \\mid y)\\:\\: \\text{for all features}$ ($i \\neq j$ and $i, j \\in \\{1, 2, ...., n\\}$). By expanding using the chain rule we obtained the following:\n",
    "\n",
    "$$ P(y \\mid x_1, x_2, ..., x_n) = \\frac{P(x_1, x_2, ..., x_n \\mid y) \\, P(y)}{P(X)} = \\frac{P(x_1 \\mid y) P(x_2 \\mid y) P(x_3 \\mid y) \\cdots P(x_n \\mid y) \\, P(y)}{P(x_1) P(x_2) P(x_3) \\cdots P(x_n)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The denominator ($P(X)$) of the Bayes rule remain the same for all classes. Therefore, we can exclude it when performing inference since it is just a term for normalization. Therefore, based on the assumption on feature independence and ignoring the denominator the NB formula can be written as follows:\n",
    "\n",
    "$$ P(\\: y \\mid x_1,x_2,...,x_n)\\: \\propto P(y) \\prod_{i=1}^{i=n} P(\\:x_i\\mid y) $$\n",
    "\n",
    "In (binary) classification tasks, the class variable $y$ has two outcomes. We need to find the class $y$ with maximum probability, i.e. $ y = argmax_y P(y) \\prod_{i=1}^{i=n} P(\\:x_i\\mid y) $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example exercise of performing inference with NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following example to strengthen our understanding in NB. The example toy dataset is for classifying whether a person owns a pet. Observations $X$ contain three features, two categorical (\"Gender\" and \"Education\") and one numerical (\"Income\"), and class label $y$ (i.e. \"Has_pet\") corresponds to whether this person owns a pet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "tab_cat = [[\"Gender\", \"Education\", \"Income\", \"Has_pet\"],\n",
    "          [\"Female\", \"University\", 103000,   \"Yes\"],\n",
    "          [\"Female\", \"HighSchool\", 90500,   \"No\"],\n",
    "          [\"Female\", \"HighSchool\", 114000,   \"No\"],\n",
    "          [\"Male\",   \"University\", 102000,   \"No\"],\n",
    "          [\"Male\",   \"University\", 75000,   \"Yes\"],\n",
    "          [\"Male\",   \"HighSchool\", 90000,   \"No\"],\n",
    "          [\"Male\",   \"HighSchool\", 85000,   \"Yes\"],\n",
    "          [\"Male\",   \"University\", 86000,   \"No\"]]\n",
    "display(HTML(tabulate.tabulate(tab_cat, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success' style=\"font-weight:bolder\">\n",
    "\n",
    "### Task 2a - Compute the Likelihood table of having pet, for each categorical feature, as well as the marginal probability.\n",
    "\n",
    "- $P(Gender|Has\\_pet)$: $P(Male|Yes)$, $P(Female|Yes)$, $P(Male|No)$, $P(Female|No)$\n",
    "    \n",
    "- $P(Education|Has\\_pet)$: $P(University|Yes)$, $P(HighSchool|Yes)$, $P(University|No)$, $P(HighSchool|No)$\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "# Example: Assuming df is your DataFrame with the dataset\n",
    "# Replace this with your actual DataFrame\n",
    "df = pd.DataFrame([\n",
    "    [\"Female\", \"University\", 103000, \"Yes\"],\n",
    "    [\"Female\", \"HighSchool\", 90500, \"No\"],\n",
    "    # ... add all rows here ...\n",
    "], columns=[\"Gender\", \"Education\", \"Income\", \"Has_pet\"])\n",
    "\n",
    "# Calculate the likelihood for the 'Gender' feature\n",
    "likelihood_gender = pd.crosstab(df['Gender'], df['Has_pet'], normalize='index')\n",
    "\n",
    "# Convert the DataFrame to a format suitable for tabulate\n",
    "table_data = [(index, *row) for index, row in likelihood_gender.iterrows()]\n",
    "headers = [\"Gender\", \"Has_pet (No)\", \"Has_pet (Yes)\"]\n",
    "\n",
    "# Display the table\n",
    "display(HTML(tabulate.tabulate(table_data, headers=headers, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success' style=\"font-weight:bolder\">\n",
    "\n",
    "### Task 2b - Compute posterior probability\n",
    "\n",
    "- $P(\\text{No}|\\text{Male})$, $P(\\text{Yes}|\\text{Female})$\n",
    "    \n",
    "- $P(\\text{Yes}|\\text{Univeristy})$, $P(\\text{No}|\\text{HighSchool})$\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "# Replace this with your actual DataFrame\n",
    "df = pd.DataFrame([\n",
    "    [\"Female\", \"University\", 103000, \"Yes\"],\n",
    "    [\"Female\", \"HighSchool\", 90500, \"No\"],\n",
    "    # ... add all rows here ...\n",
    "], columns=[\"Gender\", \"Education\", \"Income\", \"Has_pet\"])\n",
    "\n",
    "# Calculate the prior probabilities\n",
    "prior_yes = df['Has_pet'].value_counts(normalize=True)['Yes']\n",
    "prior_no = df['Has_pet'].value_counts(normalize=True)['No']\n",
    "\n",
    "# Calculate the marginal probabilities for Gender\n",
    "marginal_male = df['Gender'].value_counts(normalize=True)['Male']\n",
    "marginal_female = df['Gender'].value_counts(normalize=True)['Female']\n",
    "\n",
    "# Calculate the likelihoods (from Task 2a)\n",
    "likelihood_male_no = pd.crosstab(df['Gender'], df['Has_pet'], normalize='index').at['Male', 'No']\n",
    "likelihood_female_yes = pd.crosstab(df['Gender'], df['Has_pet'], normalize='index').at['Female', 'Yes']\n",
    "\n",
    "# Calculate the posterior probabilities\n",
    "posterior_no_given_male = (likelihood_male_no * prior_no) / marginal_male\n",
    "posterior_yes_given_female = (likelihood_female_yes * prior_yes) / marginal_female\n",
    "\n",
    "print(\"P(No | Male):\", posterior_no_given_male)\n",
    "print(\"P(Yes | Female):\", posterior_yes_given_female)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success' style=\"font-weight:bolder\">\n",
    "\n",
    "### Task 2c - Compute the Likelihood of having pet using mean, standard deviation, and normal distribution function:\n",
    "\n",
    "- Mean: $ \\mu = \\frac{1}{n} \\sum^{n}_{i=1}{x_i} $\n",
    "    \n",
    "- Standard Deviation $ \\sigma = \\left[ \\frac{1}{n-1} \\sum^{n}_{i=1}{(x_i-\\mu)^2} \\right]^\\frac{1}{2}  $\n",
    "    \n",
    "- Normal Distribution $f(x)=\\dfrac{1}{\\sigma\\sqrt{2\\pi}}\\,e^{-\\dfrac{(x-\\mu)^2}{2\\sigma{}^2}}$\n",
    "    \n",
    "Compute $P( \\text{Income}=90000 \\mid \\text{Yes})$, $P( \\text{Income}=90000 \\mid \\text{No})$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    [\"Female\", \"University\", 103000, \"Yes\"],\n",
    "    [\"Female\", \"HighSchool\", 90500, \"No\"],\n",
    "    # ... add all rows here ...\n",
    "], columns=[\"Gender\", \"Education\", \"Income\", \"Has_pet\"])\n",
    "\n",
    "# Function to calculate likelihood using Normal Distribution\n",
    "def calculate_likelihood(df, feature, target_value, class_label):\n",
    "    # Filter the DataFrame for the given class\n",
    "    class_df = df[df['Has_pet'] == class_label]\n",
    "    \n",
    "    # Calculate mean and standard deviation for the feature\n",
    "    mean = class_df[feature].mean()\n",
    "    std = class_df[feature].std()\n",
    "\n",
    "    # Calculate the probability density for the target value\n",
    "    probability_density = norm.pdf(target_value, mean, std)\n",
    "    return probability_density\n",
    "\n",
    "# Compute likelihood for Income = 90000 given 'Yes' and 'No'\n",
    "likelihood_income_yes = calculate_likelihood(df, 'Income', 90000, 'Yes')\n",
    "likelihood_income_no = calculate_likelihood(df, 'Income', 90000, 'No')\n",
    "\n",
    "print(\"P(Income = 90000 | Yes):\", likelihood_income_yes)\n",
    "print(\"P(Income = 90000 | No):\", likelihood_income_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success' style=\"font-weight:bolder\">\n",
    "\n",
    "### Task 2d - Making inference / casting predictions\n",
    "\n",
    "- $X=(Education=University, Gender=Female, Income=100000)$\n",
    "    \n",
    "- $X=(Education=HighSchool, Gender=Male, Income=92000)$\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def calculate_likelihood(df, feature, target_value, class_label):\n",
    "    # Filter the DataFrame for the given class\n",
    "    class_df = df[df['Has_pet'] == class_label]\n",
    "    \n",
    "    # Calculate mean and standard deviation for the feature\n",
    "    mean = class_df[feature].mean()\n",
    "    std = class_df[feature].std()\n",
    "\n",
    "    # Calculate the probability density for the target value\n",
    "    probability_density = norm.pdf(target_value, mean, std)\n",
    "    return probability_density\n",
    "\n",
    "def calculate_posterior(df, feature_values, class_label):\n",
    "    # Initialize posterior probability with the prior probability\n",
    "    posterior = df['Has_pet'].value_counts(normalize=True)[class_label]\n",
    "    \n",
    "    # Multiply with the likelihoods of each feature\n",
    "    for feature, value in feature_values.items():\n",
    "        likelihood = calculate_likelihood(df, feature, value, class_label)\n",
    "        posterior *= likelihood\n",
    "\n",
    "    return posterior\n",
    "\n",
    "# Feature values for the predictions\n",
    "features_1 = {'Education': 'University', 'Gender': 'Female', 'Income': 100000}\n",
    "features_2 = {'Education': 'HighSchool', 'Gender': 'Male', 'Income': 92000}\n",
    "\n",
    "# Calculate posterior probabilities for 'Yes' and 'No' for the first scenario\n",
    "posterior_yes_1 = calculate_posterior(df, features_1, 'Yes')\n",
    "posterior_no_1 = calculate_posterior(df, features_1, 'No')\n",
    "\n",
    "# Normalize probabilities\n",
    "total_1 = posterior_yes_1 + posterior_no_1\n",
    "posterior_yes_1 /= total_1\n",
    "posterior_no_1 /= total_1\n",
    "\n",
    "# Calculate posterior probabilities for 'Yes' and 'No' for the second scenario\n",
    "posterior_yes_2 = calculate_posterior(df, features_2, 'Yes')\n",
    "posterior_no_2 = calculate_posterior(df, features_2, 'No')\n",
    "\n",
    "# Normalize probabilities\n",
    "total_2 = posterior_yes_2 + posterior_no_2\n",
    "posterior_yes_2 /= total_2\n",
    "posterior_no_2 /= total_2\n",
    "\n",
    "print(\"Prediction for (Education=University, Gender=Female, Income=100000):\")\n",
    "print(\"P(Yes):\", posterior_yes_1, \"P(No):\", posterior_no_1)\n",
    "\n",
    "print(\"\\nPrediction for (Education=HighSchool, Gender=Male, Income=92000):\")\n",
    "print(\"P(Yes):\", posterior_yes_2, \"P(No):\", posterior_no_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success' style=\"font-weight:bolder\">\n",
    "\n",
    "### Task 2e (Extra Credit) Implementing a Naive Bayes Classifier and performing classification on the Iris dataset. Note that the Iris dataset only contains numerical features.\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy}\")\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
